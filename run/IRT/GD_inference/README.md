
# **ê¸°ì¶œíƒ­íƒ­ IRT - Instruction Guide**  
**Inferenceì™€ í†µí•© í…ŒìŠ¤íŠ¸ì— ê´€í•œ ë¬¸ì„œ**

---

## **Getting Started**

### **0. Prerequisites**  
Ensure you are in the correct directory before beginning the process:

```bash
conda activate lanchain
cd /root/jw/TAPTAP_IRT/run/IRT/GD_inference
```

---

### **0-1. Data Preparation**  
**Data files** are located at:  
`/root/jw/TAPTAP_IRT/run/IRT/GD`  

| File                                | Description                                            |
|-------------------------------------|--------------------------------------------------------|
| `results_NA1/{subject}/irt.params`  | Parameters for IRT                                     |
| `configs_NA1.yml`                   | Best hyper-parameters                                 |
| `processed/10_{args.subjects}_30_ratio_afterNA1.csv` | Student's solving history                    |

**Criteria for non-IRT subjects**:  
Located at: `/root/jw/TAPTAP_IRT/run/IRT/GD/non_IRT_subjects_criteria/criteria_output`  

- `{í•œêµ­ì‚¬}_results.json`: Lower and upper threshold for each subject.  

ğŸ‘‰ **Note:** Manually create `middle_high_rank.json` in the following path using the above dataset:  
`/root/jw/TAPTAP_IRT/run/IRT/GD_inference/middle_high_rank.json`  

---

### **0-2. Single Subject IRT Execution**  
ë‹¨ì¼ subjectì— ëŒ€í•œ IRT ê²°ê³¼ê°€ ê¶ê¸ˆí•˜ë‹¤ë©´:  

Run the **`incremental_inference.py`** script to get:  
```
Prints (rank, 'ìƒì¤‘í•˜', target_score, 'ëŠ¥ë ¥ì¹˜')
```

---

## **1. Get results for all solving history**  
Execute `Integration_test_with_consist_penalty.py`
**Inputs from GD:**  
1. `configs_NA1.yml`  
2. `irt.params`  
3. `10_{subjects}_problem_point_mapping_dict`  

**Additional Input:**  
- `middle_high_rank_with_penalty.json`  

**Output:**  
- **integration_test/compiled_data.csv**  
ëª¨ë“  ê³¼ëª©ì˜ 

| Columns                       | Example                                                |
|-------------------------------|--------------------------------------------------------|
| Subject                       | `í•œêµ­ì‚¬`                                               |
| Rank                          | `middle`                                               |
| Solving History               | `"[1, 1, 1, 1, 0, 0, 0, 1, 0, 0]"`                     |
| Target Score                  | `13.0`                                                 |

---

## **2. Get Threshold for IRT**  

Execute the code **`IRT_threshold.py`**.

**Inputs:**  
1. `irt_subjects list`  
2. `GD/detailed/10_{subject}_p_theta_response.json`  
3. `integration_test/compiled_data.csv`  

**Output Example:**  
```json
"ë…ì„œ,ë¬¸í•™": [
    -0.3161628246307373,
    0.0112729333341121
]
```

ğŸ‘‰ **Note:** Manually update the results of `middle_high_rank.json` for IRT subjects.

## **3. Rerun `integration_test_with_consist_penalty.py`**

Re-run with updated `middle_high_rank.json` will give the final `compiled_data.csv`.

---

## **í†µí•© í…ŒìŠ¤íŠ¸**  
ğŸ“ Look into the folder **`test_scripts`** for post-hoc analysis.

ê° ë¬¸ì œë¥¼ ë§ì¶œ í™•ë¥  p_{question}ì„ ê°€ì§€ê³  simulation í•´ì„œ ë§Œë“  ê°’ì— ìƒ,ì¤‘,í•˜ë¥¼ 30%ì”© ë°°ë¶„í–ˆë‹¤. 
ë”°ë¼ì„œ, 10ë¬¸ì œ ì¤‘ ì•½ 70%ë¥¼ ë§ì¶°ì•¼ë§Œ 'ì¤‘'ì´ ëœ° ê²ƒì´ë‹¤.  

---

### **1. Get Answers for Each Subject**  

Execute the script: **`get_answers.py`**  

**Output:**  
- Generates: `GD_inference/integration_test/filtered_csv_outputs` for each subject.

---

### **2. Get Results for All Subjects by Solving History**  

Run the script: **`get_rank_by_response.py`**

**Output:**  
Generates:  
`solving_history_" + "_".join(map(str, solving_history)) + ".csv`  

**Example Result:**  

| Subject            | Rank  | Target Score              |
|---------------------|-------|---------------------------|
| `ìˆ˜í•™â… ,ìˆ˜í•™â…¡`      | `low` | `-1.1868665218353271`     |
| `ë…í•´,ë“£ê¸°`         | `low` | `-0.7025999426841736`     |

---

**End of Document** ğŸš€  
